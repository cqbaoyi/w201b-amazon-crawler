# Python Web Crawler Learning Project

## Project Focus
Lightweight Python web crawler for learning Amazon data extraction.

## Key Principles
- Clean, readable code for learning
- Always check and respect robots.txt before crawling
- Respect rate limits (1-3 second delays between requests)
- Use proper error handling for network requests
- Parse HTML with BeautifulSoup, not regex
- Store data in JSON/CSV format

## Libraries
- requests: HTTP requests
- beautifulsoup4: HTML parsing
- playwright: For JavaScript-heavy pages
- urllib.robotparser: Check robots.txt compliance

## Code Style
- Use type hints and docstrings
- Keep functions small and focused
- Handle errors gracefully with try-except
- Use meaningful variable names
